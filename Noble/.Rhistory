ggplot2::ggsave(filename = paste0(site, "_", bgn.month, "-", end.month, "_flow.png"), path = paste0(save.dir, "/"), plot = plot, device = 'png', width = 5, height = 3.5, units = "in", dpi=300)
plot=ggplot(melt.flow, aes(x=Date, y = value/3, fill=factor(variable)))+
theme_bw()+
geom_bar(stat = 'identity', width = "100%")+
scale_y_continuous(limits = c(0,100))+
theme(axis.text.x =element_blank())+
ggplot2::scale_fill_manual(name = "Flow Quality Metrics", values=niceColors)+
labs(x=paste0(zoo::as.yearmon(bgn.month, format="%Y-%m"), " to ", zoo::as.yearmon(end.month, format="%Y-%m")), y="Site wide flow flagging (%)", title=paste0(domn, "-", site))
plot
plot=ggplot(melt.flow, aes(x=Date, y = value/3, fill=factor(variable)))+
theme_bw()+
geom_bar(stat = 'identity', width = 10000)+
scale_y_continuous(limits = c(0,100))+
theme(axis.text.x =element_blank())+
ggplot2::scale_fill_manual(name = "Flow Quality Metrics", values=niceColors)+
labs(x=paste0(zoo::as.yearmon(bgn.month, format="%Y-%m"), " to ", zoo::as.yearmon(end.month, format="%Y-%m")), y="Flow flagging distribution (% of measuremnts at site)", title=paste0(domn, "-", site))
ggplot2::ggsave(filename = paste0(site, "_", bgn.month, "-", end.month, "_flow.png"), path = paste0(save.dir, "/"), plot = plot, device = 'png', width = 5, height = 3.5, units = "in", dpi=300)
plot=ggplot(melt.flow, aes(x=Date, y = value/3, fill=factor(variable)))+
theme_bw()+
geom_bar(stat = 'identity', width = 10000)+
scale_y_continuous(limits = c(0,100))+
theme(axis.text.x =element_blank())+
ggplot2::scale_fill_manual(name = "Flow Quality Metrics", values=niceColors)+
labs(x=paste0(zoo::as.yearmon(bgn.month, format="%Y-%m"), " to ", zoo::as.yearmon(end.month, format="%Y-%m")), y="Flagging distribution (% of measuremnts)", title=paste0(domn, "-", site))
ggplot2::ggsave(filename = paste0(site, "_", bgn.month, "-", end.month, "_flow.png"), path = paste0(save.dir, "/"), plot = plot, device = 'png', width = 5, height = 3.5, units = "in", dpi=300)
resultFile = paste(testFullDir,"/Common/", "results.csv", sep="")
test <- "TIS Fan Aspitation System Performance "
testSubDir <- "TisFanAspirationSystemPerformance"
if(grepl("darwin", version$os))
{
dirCommBase<-"/Volumes/neon/Science/Science Commissioning Archive/SiteAndPayload/"
}else{
dirCommBase<-"N:/Science/Science Commissioning Archive/SiteAndPayload/"
}
# should not need to edit these...
myTitle <- paste("TIS Commissioning Test Report:", test, "Assessment")
rmdFile <- paste( testSubDir, ".Rmd", sep="")
testFullDir <- paste(dirCommBase, testSubDir, sep="")
resultFile = paste(testFullDir,"/Common/", "results.csv", sep="")
results = data.frame(read.csv(resultFile, header=TRUE), stringsAsFactors = FALSE)
source(paste(dirCommBase, "exclude_script.R", sep = ""))
# Important! Only reads the most recent results data per site into the RMD #
siteList = (unique(results$site))
numbSites = as.numeric(length(siteList))
results=results[with(results, order(site, time_performed)),]
parsed.results=data.frame()
for (k in 1:numbSites) {
siteIndex=grep(pattern = siteList[k], results$site)
siteOnly =results[siteIndex,]
siteOut=siteOnly[which.max(as.POSIXct(siteOnly$time_performed)),]
parsed.results=rbind(parsed.results, siteOut)
}
# construct a data frame of data product names and their corresponding DP IDs:
nneoDPs=data.frame(cbind(name=nneo::nneo_products()$productName, code=nneo::nneo_products()$productCode))
nneoDPs$name=gsub("\\(||\\)", "", nneoDPs$name)
onlyL1=grep(nneoDPs$code, pattern = "DP1")
nneoDPs=nneoDPs[onlyL1,]
#### _____ TO HERE
View(parsed.results)
currDomn = nneo_site(currSite)$domainCode # Find the corresponding domain number
nneoDPs=data.frame(cbind(name=nneo::nneo_products()$productName, code=nneo::nneo_products()$productCode))
nneoDPs=data.frame(cbind(name=nneo::nneo_products()$productName, code=nneo::nneo_products()$productCode))
nneoDPs$name=gsub("\\(||\\)", "", nneoDPs$name)
onlyL1=grep(nneoDPs$code, pattern = "DP1")
i=1
a
resultLeng=length(parsed.results$site)
i=0
i=1
currSite = as.character(parsed.results$site[i]) # set the current site being examined (in order in results file)
currDP = as.character(parsed.results$data_product[i]) # Current data product
currDomn = nneo_site(currSite)$domainCode # Find the corresponding domain number
currBgnDate = zoo::as.yearmon(parsed.results$begin_month[i]) # set the current commissioning start date (in order in results file)
currEndDate = zoo::as.yearmon(parsed.results$end_month[i]) # set the current commissioning end date (in order in results file)
userSpan=parsed.results$days_tested[i]
currNumbDay = userSpan
currPcntPass = as.numeric(parsed.results$percent_pass[i])
currTestDate = (parsed.results$time_performed[i])
dataDir = paste(dirCommBase, testSubDir,"/", currDomn, "-", currSite, "/", sep="") # set file path to look for test file
fileList = unlist(list.files(dataDir)) # get list of files to find from
dataFiles=fileList[grep(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileDeets=file.info(paste(dataDir, dataFiles, sep="/"))
fileDeets=data.frame(cbind(dataFiles, fileDeets))
fileDeets = fileDeets[with(fileDeets, order(atime)), ]
fileUsed=fileDeets$dataFiles[which.max(fileDeets$atime)]
fullLoc = paste0(currDomn, "-", parsed.results$site[i]) # Make full site code
passTH = round(parsed.results$pass_threshold[i], digits = 2)
out = c(out, knit_expand('chap5result.Rmd')) ## Output chapter 5 RMD code with data to master RMD
cat(knit(text=unlist(paste(out, collapse = '\n')), quiet=TRUE))
out = NULL #reset the output of the loop to null, so duplicates aren't printed
for (i in 1:resultLeng) {
out = NULL #reset the output of the loop to null, so duplicates aren't printed
#---------- Site and variable values -----------#
currSite = as.character(parsed.results$site[i]) # set the current site being examined (in order in results file)
currDP = as.character(parsed.results$data_product[i]) # Current data product
currDomn = nneo_site(currSite)$domainCode # Find the corresponding domain number
#------------- Time-related values -------------#
currBgnDate = zoo::as.yearmon(parsed.results$begin_month[i]) # set the current commissioning start date (in order in results file)
currEndDate = zoo::as.yearmon(parsed.results$end_month[i]) # set the current commissioning end date (in order in results file)
userSpan=parsed.results$days_tested[i]
currNumbDay = userSpan
#----------- Testing-related values ------------#
currPcntPass = as.numeric(parsed.results$percent_pass[i])
currTestDate = (parsed.results$time_performed[i])
#------------- File-related values -------------#
dataDir = paste(dirCommBase, testSubDir,"/", currDomn, "-", currSite, "/", sep="") # set file path to look for test file
fileList = unlist(list.files(dataDir)) # get list of files to find from
dataFiles=fileList[grep(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileDeets=file.info(paste(dataDir, dataFiles, sep="/"))
fileDeets=data.frame(cbind(dataFiles, fileDeets))
fileDeets = fileDeets[with(fileDeets, order(atime)), ]
fileUsed=fileDeets$dataFiles[which.max(fileDeets$atime)]
fullLoc = paste0(currDomn, "-", parsed.results$site[i]) # Make full site code
#excluder(exFile=paste(dataDir, "exclude.csv", sep=""), dpID = currDPID)
#------------- Set Test thresholds -------------#
passTH = round(parsed.results$pass_threshold[i], digits = 2)
#------------- Output the results --------------#
out = c(out, knit_expand('chap5result.Rmd')) ## Output chapter 5 RMD code with data to master RMD
cat(knit(text=unlist(paste(out, collapse = '\n')), quiet=TRUE))
}
for (i in 1:resultLeng) {
out = NULL #reset the output of the loop to null, so duplicates aren't printed
#---------- Site and variable values -----------#
currSite = as.character(parsed.results$site[i]) # set the current site being examined (in order in results file)
currDP = as.character(parsed.results$data_product[i]) # Current data product
currDomn = nneo_site(currSite)$domainCode # Find the corresponding domain number
#------------- Time-related values -------------#
currBgnDate = zoo::as.yearmon(parsed.results$begin_month[i]) # set the current commissioning start date (in order in results file)
currEndDate = zoo::as.yearmon(parsed.results$end_month[i]) # set the current commissioning end date (in order in results file)
userSpan=parsed.results$days_tested[i]
currNumbDay = userSpan
#----------- Testing-related values ------------#
currPcntPass = as.numeric(parsed.results$percent_pass[i])
currTestDate = (parsed.results$time_performed[i])
#------------- File-related values -------------#
dataDir = paste(dirCommBase, testSubDir,"/", currDomn, "-", currSite, "/", sep="") # set file path to look for test file
fileList = unlist(list.files(dataDir)) # get list of files to find from
dataFiles=fileList[grep(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileDeets=file.info(paste(dataDir, dataFiles, sep="/"))
fileDeets=data.frame(cbind(dataFiles, fileDeets))
fileDeets = fileDeets[with(fileDeets, order(atime)), ]
fileUsed=fileDeets$dataFiles[which.max(fileDeets$atime)]
fullLoc = paste0(currDomn, "-", parsed.results$site[i]) # Make full site code
#excluder(exFile=paste(dataDir, "exclude.csv", sep=""), dpID = currDPID)
#------------- Set Test thresholds -------------#
passTH = round(parsed.results$pass_threshold[i], digits = 2)
#------------- Output the results --------------#
#out = c(out, knit_expand('chap5result.Rmd')) ## Output chapter 5 RMD code with data to master RMD
#cat(knit(text=unlist(paste(out, collapse = '\n')), quiet=TRUE))
}
print(i)
for (i in 1:resultLeng) {
out = NULL #reset the output of the loop to null, so duplicates aren't printed
print(i)
#---------- Site and variable values -----------#
currSite = as.character(parsed.results$site[i]) # set the current site being examined (in order in results file)
currDP = as.character(parsed.results$data_product[i]) # Current data product
currDomn = nneo_site(currSite)$domainCode # Find the corresponding domain number
#------------- Time-related values -------------#
currBgnDate = zoo::as.yearmon(parsed.results$begin_month[i]) # set the current commissioning start date (in order in results file)
currEndDate = zoo::as.yearmon(parsed.results$end_month[i]) # set the current commissioning end date (in order in results file)
userSpan=parsed.results$days_tested[i]
currNumbDay = userSpan
#----------- Testing-related values ------------#
currPcntPass = as.numeric(parsed.results$percent_pass[i])
currTestDate = (parsed.results$time_performed[i])
#------------- File-related values -------------#
dataDir = paste(dirCommBase, testSubDir,"/", currDomn, "-", currSite, "/", sep="") # set file path to look for test file
fileList = unlist(list.files(dataDir)) # get list of files to find from
dataFiles=fileList[grep(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileDeets=file.info(paste(dataDir, dataFiles, sep="/"))
fileDeets=data.frame(cbind(dataFiles, fileDeets))
fileDeets = fileDeets[with(fileDeets, order(atime)), ]
fileUsed=fileDeets$dataFiles[which.max(fileDeets$atime)]
fullLoc = paste0(currDomn, "-", parsed.results$site[i]) # Make full site code
#excluder(exFile=paste(dataDir, "exclude.csv", sep=""), dpID = currDPID)
#------------- Set Test thresholds -------------#
passTH = round(parsed.results$pass_threshold[i], digits = 2)
#------------- Output the results --------------#
#out = c(out, knit_expand('chap5result.Rmd')) ## Output chapter 5 RMD code with data to master RMD
#cat(knit(text=unlist(paste(out, collapse = '\n')), quiet=TRUE))
}
bad.sites=c("ABBY", "SJER", "NOGP", "SRER")
for(i in 1:length(bad.sites)){
sink<-try(
Noble::fan.test(site = bad.sites[i], bgn.month = bgn.month, end.month = end.month, save.dir=testFullDir)
)
}
for (i in 1:resultLeng) {
out = NULL #reset the output of the loop to null, so duplicates aren't printed
print(i)
#---------- Site and variable values -----------#
currSite = as.character(parsed.results$site[i]) # set the current site being examined (in order in results file)
currDP = as.character(parsed.results$data_product[i]) # Current data product
currDomn = nneo_site(currSite)$domainCode # Find the corresponding domain number
#------------- Time-related values -------------#
currBgnDate = zoo::as.yearmon(parsed.results$begin_month[i]) # set the current commissioning start date (in order in results file)
currEndDate = zoo::as.yearmon(parsed.results$end_month[i]) # set the current commissioning end date (in order in results file)
userSpan=parsed.results$days_tested[i]
currNumbDay = userSpan
#----------- Testing-related values ------------#
currPcntPass = as.numeric(parsed.results$percent_pass[i])
currTestDate = (parsed.results$time_performed[i])
#------------- File-related values -------------#
dataDir = paste(dirCommBase, testSubDir,"/", currDomn, "-", currSite, "/", sep="") # set file path to look for test file
fileList = unlist(list.files(dataDir)) # get list of files to find from
dataFiles=fileList[grep(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileDeets=file.info(paste(dataDir, dataFiles, sep="/"))
fileDeets=data.frame(cbind(dataFiles, fileDeets))
fileDeets = fileDeets[with(fileDeets, order(atime)), ]
fileUsed=fileDeets$dataFiles[which.max(fileDeets$atime)]
fullLoc = paste0(currDomn, "-", parsed.results$site[i]) # Make full site code
#excluder(exFile=paste(dataDir, "exclude.csv", sep=""), dpID = currDPID)
#------------- Set Test thresholds -------------#
passTH = round(parsed.results$pass_threshold[i], digits = 2)
#------------- Output the results --------------#
#out = c(out, knit_expand('chap5result.Rmd')) ## Output chapter 5 RMD code with data to master RMD
#cat(knit(text=unlist(paste(out, collapse = '\n')), quiet=TRUE))
}
data <- readr::read_csv("~/Dropbox/Shared Docs for Manuscript/Robert's Plots/PARAFAC v Time/data.csv")
data$`Date Collected`=as.Date(data$`Date Collected`, format = "%m/%d/%y")
data=data[-which(data$FI<=1.3),]
data=data.frame(data, shape=rep("", times=length(data[,1])))
data=data.frame(data, color=rep("", times=length(data[,1])))
ggplot(data = data, aes(x = SQ, y=FI, color=Watershed, shape=Watershed))+
geom_point()+
scale_shape_manual(name="Watershed",
values=shapeList,
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_grey()+
scale_fill_manual(name="Watershed",
values=factor(Watershed),
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_light()+
theme(text=element_text(family="Times New Roman", size=18))+
labs(x="SQ1/(SQ1+SQ2)", y="FI")+
geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1))+
annotate(geom = "text", label= paste0("R-squared: ", r_sqr), x=0.5, y = 1.65)+
annotate(geom = "text", label= trendLine, x=0.5, y = 1.68)
data$`Date Collected`=as.Date(data$`Date Collected`, format = "%m/%d/%y")
data=data[-which(data$FI<=1.3),]
data=data.frame(data, shape=rep("", times=length(data[,1])))
data=data.frame(data, color=rep("", times=length(data[,1])))
data$shape[data$Watershed=="WS3-T"]=3
data$shape[data$Watershed=="WS4-R"]=7
data$shape[data$Watershed=="EB-R"]=8
data$shape[data$Watershed=="WB-T"]=12
data$color[data$Watershed=="WS3-T"]="#3a8a9e"
data$color[data$Watershed=="WS4-R"]="#3a589e"
data$color[data$Watershed=="EB-R"]="#d64042"
data$color[data$Watershed=="WB-T"]="#d68840"
r_sqr="0.61"
trendLine="y= -0.941x + 1.89"
#niceColors<-c("#3a8a9e",  "#3a589e", "#d68840", "#d64042")
shapeList=c(16, 1, 2, 17)
ggplot(data = data, aes(x = SQ, y=FI, color=Watershed, shape=Watershed))+
geom_point()+
scale_shape_manual(name="Watershed",
values=shapeList,
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_grey()+
scale_fill_manual(name="Watershed",
values=factor(Watershed),
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_light()+
theme(text=element_text(family="Times New Roman", size=18))+
labs(x="SQ1/(SQ1+SQ2)", y="FI")+
geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1))+
annotate(geom = "text", label= paste0("R-squared: ", r_sqr), x=0.5, y = 1.65)+
annotate(geom = "text", label= trendLine, x=0.5, y = 1.68)
shapeList=c(16, 1, 2, 17)
ggplot(data = data, aes(x = SQ, y=FI, color=Watershed, shape=Watershed))+
geom_point()+
scale_shape_manual(name="Watershed",
values=shapeList,
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_grey()+
scale_fill_manual(name="Watershed",
values=factor(Watershed),
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_light()+
theme(text=element_text(family="Times New Roman", size=18))+
labs(x="SQ1/(SQ1+SQ2)", y="FI")+
geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1))+
annotate(geom = "text", label= paste0("R-squared: ", r_sqr), x=0.5, y = 1.65)+
annotate(geom = "text", label= trendLine, x=0.5, y = 1.68)
data <- readr::read_csv("~/Dropbox/Shared Docs for Manuscript/Robert's Plots/PARAFAC v Time/data.csv")
#artinsinal data curation
data$`Date Collected`=as.Date(data$`Date Collected`, format = "%m/%d/%y")
data=data[-which(data$FI<=1.3),]
data=data.frame(data, shape=rep("", times=length(data[,1])))
data=data.frame(data, color=rep("", times=length(data[,1])))
data$shape[data$Watershed=="WS3-T"]=3
data$shape[data$Watershed=="WS4-R"]=7
data$shape[data$Watershed=="EB-R"]=8
data$shape[data$Watershed=="WB-T"]=12
data$color[data$Watershed=="WS3-T"]="#3a8a9e"
data$color[data$Watershed=="WS4-R"]="#3a589e"
data$color[data$Watershed=="EB-R"]="#d64042"
data$color[data$Watershed=="WB-T"]="#d68840"
r_sqr="0.61"
trendLine="y= -0.941x + 1.89"
#niceColors<-c("#3a8a9e",  "#3a589e", "#d68840", "#d64042")
shapeList=c(16, 1, 2, 17)
ggplot(data = data, aes(x = SQ, y=FI, color=Watershed, shape=Watershed))+
geom_point()+
scale_shape_manual(name="Watershed",
values=shapeList,
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_grey()+
scale_fill_manual(name="Watershed",
values=factor(Watershed),
labels=c("EB-R", "WB-T", "WS3-T", "WS4-R"))+
theme_light()+
theme(text=element_text(family="Times New Roman", size=18))+
labs(x="SQ1/(SQ1+SQ2)", y="FI")+
geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1))+
annotate(geom = "text", label= paste0("R-squared: ", r_sqr), x=0.5, y = 1.65)+
annotate(geom = "text", label= trendLine, x=0.5, y = 1.68)
view(data)
write.csv("./R_FI_SQ_data.csv", row.names = F, x = data)
fileList=c("hshhshs", "shjshs")
fileList[grep(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileList[grepl(pattern="DP1.00002.001||DP1.00003.001", fileList)]
fileList[grepl(pattern="DP1.00002.001|DP1.00003.001", x = fileList)]
fileList[grep(pattern="DP1.00002.001|DP1.00003.001", x = fileList)]
uscrn=read.csv("./data/uscrn.csv")
colnames(uscrn)=c("Fan Speed (RPM)", "Flow (CFM)")
knitr::kable(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c", format = "latex",)
#plot(uscrn)
knitr::kable(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c", format = "latex",)
knitr::kable(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c",)
options(xtable.type)="latex"
pander::
install.packages(pander)
"pander"
install.packages("pander")
pander::pander(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c")
pander::pander(eng.data, caption = "Measured flow rates (in cubic feet per minute) and turbine speeds (in revolutions per minute) for a range fan speeds in the MetOne 076B 7308 Aspirated Solar Sheld Assembly (provided by NEON Engineering Dept).", align = "c", format = "latex")
eng.data=read.csv("./data/engFanData.csv")
colnames(eng.data)=c("Fan Speed", "Flow (CFM)", "Turbine Speed (RMP)")
pander::pander(eng.data, caption = "Measured flow rates (in cubic feet per minute) and turbine speeds (in revolutions per minute) for a range fan speeds in the MetOne 076B 7308 Aspirated Solar Sheld Assembly (provided by NEON Engineering Dept).", align = "c", format = "latex")
pander::panderOptions("table.style", "latex")
pander::pander(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c")
pander::panderOptions("table.style", "latex")
pander::pander(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c")
?panderOptions
pander::panderOptions("table.style", "rmarkdown")
pander::pander(uscrn, caption = "Fan speeds (in revolutions per minute) and corresponding modeled flow (in cubic feet per minute) data provided by Tilden Meyer of the 2017 Science, Technology & Education Advisory Committee.", align = "c")
getwd()
dir="Users/rlee/Dropbox/NEON/WetDepSensorCheck/"
dir.create(dir)
dir="/Users/rlee/Dropbox/NEON/WetDepSensorCheck/"
dir.create(dir)
rh=read.csv(paste0(dir, "RH.csv"))
wdp=read.csv(paste0(dir,"wdp.csv"))
data=data.frame(cbind(Time=as.POSIXct(wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.time),
`Wet Dep Temp`=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.data,
`Air Temp`=rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.data))
data=data.frame(cbind(Time=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.time,
`Wet Dep Temp`=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.data,
`Air Temp`=rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.data))
wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.time
wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.data
rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.data
qplot(x=rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.time, y=rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.data)+qplot(x=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.time, y=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.data)
qplot(x=rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.time, y=rh$NEON.D09.WOOD.DP0.00098.001.01309.000.040.000.data)qplot(x=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.time, y=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.data)
qplot(x=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.time, y=wdp$NEON.D09.WOOD.DP0.00013.001.01818.000.040.000.data)
metScanR::mapSiteFinder(metScanR::getNearby(siteID = "NEON:CPER"))
metScanR::mapSiteFinder(metScanR::getNearby(siteID = "NEON:CPER", radius = 30))
?sample
?leaflet::addProviderTiles
saveDir = getwd() # Specify outpud directory for saved images
# Map info:
country = "United States"
lng = -98
lat = 20
zoom = 6
#Time Info
startDate = "1740-12-31"
endDate = "1840-12-31"
by= "10 years"
## Start of script
# Generate a lisy of endDates
dates=as.list(as.character(seq.Date(from = as.Date(startDate), to=as.Date(endDate), by = by)))
maps=lapply(dates,
function(x)
leaflet::addProviderTiles(leaflet::setView(
map =metScanR::mapSiteFinder(metScanR::siteFinder(country=country, endDate = x)),
lng = lng,
lat = lat,
zoom = zoom
), provider = "Esri.OceanBasemap"  ### If you want to switch tiles, check out: http://leaflet-extras.github.io/leaflet-providers/preview/
)
)
for(i in 1:length(dates)){
mapview::mapshot(x = maps[[i]],
file = paste0(save.dir, dates[[i]], ".png")
)
}
getwd()
save.dir
# Template RHL 2017-11-01
# Use this script to
require(mapview)
require(metScanR)
saveDir = "./" # Specify outpud directory for saved images
# Map info:
country = "United States"
lng = -98
lat = 20
zoom = 3
#Time Info
startDate = "1740-12-31"
endDate = "1840-12-31"
by= "10 years"
## Start of script
# Generate a lisy of endDates
dates=as.list(as.character(seq.Date(from = as.Date(startDate), to=as.Date(endDate), by = by)))
maps=lapply(dates,
function(x)
leaflet::addProviderTiles(leaflet::setView(
map =metScanR::mapSiteFinder(metScanR::siteFinder(country=country, endDate = x)),
lng = lng,
lat = lat,
zoom = zoom
), provider = "Esri.OceanBasemap"  ### If you want to switch tiles, check out: http://leaflet-extras.github.io/leaflet-providers/preview/
)
)
for(i in 1:length(dates)){
mapview::mapshot(x = maps[[i]],
file = paste0(saveDir, "/", dates[[i]], ".png")
)
}
list.dirs("./")
list.files("./")
# Template RHL 2017-11-01
# Use this script to
require(mapview)
require(metScanR)
saveDir = "./" # Specify outpud directory for saved images
# Map info:
country = "United States"
lng = -98
lat = 40
zoom = 3
#Time Info
startDate = "1740-12-31"
endDate = "1840-12-31"
by= "10 years"
#### Start of script ####
# Generate a lisy of endDates
dates=as.list(as.character(seq.Date(from = as.Date(startDate), to=as.Date(endDate), by = by)))
# makes a list of map objects. Takes a little while!
maps=lapply(dates,
function(x)
leaflet::addProviderTiles(leaflet::setView(
map =metScanR::mapSiteFinder(metScanR::siteFinder(country=country, endDate = x)),
lng = lng,
lat = lat,
zoom = zoom
), provider = "Esri.OceanBasemap"  ### If you want to switch tiles, check out: http://leaflet-extras.github.io/leaflet-providers/preview/
)
)
# Saves pngs of maps, also takes a while.
for(i in 1:length(dates)){
mapview::mapshot(x = maps[[i]],
file = paste0(saveDir, "/", dates[[i]], ".png")
)
}
#Reminder to clean up any folders generated in saving these PNGs (it can happen, will be in the same directory).
# Template RHL 2017-11-01
# Use this script to
require(mapview)
#install.packages("mapview")
require(metScanR)
saveDir = "./" # Specify output directory for saved images
# Map info:
country = "United States"
lng = -98
lat = 45
zoom = 3
#Time Info
startDate = "1770-12-31"
endDate = "1900-12-31"
by= "10 years"
#### Start of script ####
# Generate a list of endDates
dates=as.list(as.character(seq.Date(from = as.Date(startDate), to=as.Date(endDate), by = by)))
# makes a list of map objects. Takes a little while!
maps=lapply(dates,
function(x)
leaflet::addProviderTiles(leaflet::setView(
map =metScanR::mapSiteFinder(metScanR::siteFinder(country=country, endDate = x)),
lng = lng,
lat = lat,
zoom = zoom
), provider = "Esri.OceanBasemap"  ### If you want to switch tiles, check out: http://leaflet-extras.github.io/leaflet-providers/preview/
)
)
# Saves pngs of maps, also takes a while.
for(i in 1:length(dates)){
mapview::mapshot(x = maps[[i]],
file = paste0(saveDir, "/", dates[[i]], ".png")
)
}
#Reminder to clean up any folders generated in saving these PNGs (it can happen, will be in the same directory).
Noble:::dpID
library(Noble)
staReso<-read.csv("/Dropbox/GitHub/external-sites/documents/stationResolutionMap.csv",stringsAsFactors = F)
staReso<-read.csv("/Users/rlee/Dropbox/GitHub/external-sites/documents/stationResolutionMap.csv",stringsAsFactors = F)
View(staReso)
