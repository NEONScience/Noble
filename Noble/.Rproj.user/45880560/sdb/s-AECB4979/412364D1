{
    "collab_server" : "",
    "contents" : "############################################################################################\n#' @title  Downloads data for a specified data product or products, and saves the data to a specified directory\n\n#' @author Robert Lee \\email{rlee@battelleecology.org}\\cr\n\n#' @description For the specified dates, site, package parameters, and data product or name of family of data products,\n#' data are downloaded and saved to the specifed directory.\n#'\n#' @param \\code{site} Parameter of class character. The NEON site data should be downloaded for.\n#' @param \\code{dpID} Parameter of class character. The name of the data product to pull data, or a keyword for a family of data products, e.g. \"wind\" will pull for 2D and 3D wind data products.\n#' @param \\code{bgn.month} Parameter of class character. The year-month (e.g. \"2017-01\") of the first month to get data for.\n#' @param \\code{end.month} Parameter of class character. The year-month (e.g. \"2017-01\") of the last month to get data for.\n#' @param \\code{time.agr} Parameter of class numeric. The data agregation interval requested, must be 1, 2, or 30.\n#' @param \\code{package} Parameter of class character. Optional. The type of data package to be returned If not specified, defaults to basic.\n#' @param \\code{save.dir} Parameter of class character. The local directory where data files should be saved.\n#'\n#' @return Writes data files to the specified directory.\n\n#' @keywords process quality, data quality, gaps, commissioning\n\n#' @examples\n#' #Make a temporary direcotry for the example:\n#' tempDir<- tempdir()\n#' data.pull(site = \"CPER\", dpID = \"Radiation\", bgn.month = \"2017-02\", end.month = \"2017-03\", time.agr = 30, package=\"expanded\", save.dir = tempDir)\n#' data.pull(site = \"CPER\", dpID = \"DP1.00002.001\", bgn.month = \"2017-04\", end.month = \"2017-05\", time.agr = 30, package=\"basic\", save.dir= tempDir)\n\n\n#' @seealso Currently none\n\n#' @export\n\n# changelog and author contributions / copyrights\n#   Robert Lee (2017-07-18)\n#     original creation\n#\n##############################################################################################\n\n\n###TEST BLOCK####\nsite=\"CPER\"\ndpID=\"DP1.00002.001\"\nbgn.month=\"2017-06\"\nend.month=\"2017-06\"\ntime.agr=30\npackage=\"basic\"\n\n\ndata.pull = function(site = \"JORN\", dpID = \"DP1.00001.001\", bgn.month = \"2017-02\", end.month = \"2017-04\", time.agr = 30, package=\"basic\", save.dir){\n\n    require(jsonlite)\n    #require(nneo)\n    require(lubridate)\n\n    #read in current TIS site info\n    is_site_config<-Noble::is_site_config\n    curr_site_config=is_site_config[which(is_site_config$SiteID==site),]\n\n    #make sure to request valid packages!\n    valid.pack<-c(\"basic\", \"expanded\")\n    save.dir = paste0(save.dir, \"/\")\n\n    if(!dir.exists(save.dir)){stop(\"Invalid directory specified! Please correct the parameter given to 'save.dir'.\")}\n\n    if(missing(package)){package<-\"basic\"}\n    if(!package %in% valid.pack){stop(\"Please specify a package of 'basic' or 'expaned'\")}\n\n    #figure out if a code or keyword for a data product has been passed to the fucntion.\n    if(!grepl(pattern = \"^DP1.*\", x=dpID)){\n\n        stop(\"Please enter a data product code, eg: dpID='DP1.00001.001'.\")\n    }\n\n    # Make a sequence of dates and times for the requested period\n    bgn_temp <- as.Date(paste0(bgn.month, \"-01\"), tz=\"UTC\")\n    end_temp <- as.Date(paste0(end.month, \"-01\"), tz=\"UTC\")\n    bgn_temp <- as.POSIXct(paste0(bgn.month, \"-01\"), tz=\"UTC\")\n    end_temp<- as.POSIXlt(paste0(end_temp, \"-01\"), tz=\"UTC\")\n    end_temp$mon<-end_temp$mon+1\n    end_temp<-end_temp-lubridate::minutes(time.agr)-lubridate::seconds(1)\n\n    ref_seq<-Noble::help.time.seq(from=bgn_temp, to=end_temp, time.agr = time.agr)\n\n    # Get site metadata\n    call.df=Noble:::.gen.call.df(bgn.month=bgn.month,\n                                 end.month=end.month,\n                                 site=site, dpID=dpID,\n                                 time.agr=time.agr,\n                                 package=package)\n\n    #Make our start timestamps, which data are matched to.\n    start_time_stamps<-as.data.frame(ref_seq)\n\n    ##### Data Pull section #####\n    #Set the expected data filename for the data product\n    file.name<- paste0(\"NEON.\", curr_site_config$Domain,\".\", site, \".\", dpID, \"_REQ_\", bgn_temp, \"_\", as.character(as.Date(end_temp)), \"_\", time.agr, \"min_\", package,\".csv.gz\")\n\n    #if we're missing the expected file, download the data\n    if(!file.exists(paste0(save.dir, file.name))){\n\n        #how many locations exist for the product, according to the API? Make a list of those\n        loc_per_dp<-unique(call.df$loc_list[call.df$dp_list==dpID])\n\n        # if we're going around the loop again, get rid of the previous DP's data\n        if(exists(\"full.df\")){\n            rm(full.df)\n        }\n\n        # Loop for gettng one location's DP data- (eg. ML1's data)\n        for(j in 1:length(loc_per_dp)){\n\n            #set location to first in list\n            temp_loc<-loc_per_dp[j]\n\n            #pull out all URLs for the DP we need\n            temp_urls_per_dp<-call.df$url_list[which(call.df$loc_list==temp_loc & call.df$dp_list==dpID)]\n\n            if(exists(\"temp.dp.data\")){\n                rm(temp.dp.data)\n            }\n\n            for(k in 1:length(temp_urls_per_dp)){\n\n                #clear out our temp dp data object, before adding to it.\n                if(!exists(\"temp.dp.data\")){\n                    temp.dp.data<-read.csv(file=as.character(temp_urls_per_dp[k]), stringsAsFactors = F)\n\n                    #\n                }else{\n                    #Read in a month's worth of data\n                    temp.data<-read.csv(file=as.character(temp_urls_per_dp[k]), stringsAsFactors = F)\n                    temp.dp.data<-try(rbind(temp.dp.data, temp.data))\n                }\n\n            }\n            # Convert returned data to POSIX\n            temp.dp.data$startDateTime<-as.POSIXct(temp.dp.data$startDateTime, format= \"%Y-%m-%dT%H:%M:%SZ\", tz=\"UTC\")\n\n            # Add loacation data to the column names, then clean up the date/time names\n            colnames(temp.dp.data)<-paste0(colnames(temp.dp.data),\".\", temp_loc)\n            colnames(temp.dp.data)[grepl(pattern = \"*Time*\", x=colnames(temp.dp.data))]=\n                gsub(pattern = \"\\\\d||\\\\.\", replacement = \"\",\n                     x = colnames(temp.dp.data[,grepl(pattern = \"*Time*\", x=colnames(temp.dp.data))]))\n\n\n            if(!exists(\"full.df\")){\n                full.df<-data.frame(matrix(NA, nrow = length(ref_seq), ncol = length(colnames(temp.dp.data))))\n                names(full.df)<-colnames(temp.dp.data)\n                full.df[,1]<- as.POSIXct(ref_seq)\n\n\n                #print(length(full.df[,1]))\n\n                # New fix?\n                full.df[which(full.df[,1] %in% temp.dp.data$startDateTime),]<-temp.dp.data[which(temp.dp.data$startDateTime %in% full.df[,1]),]\n\n                # The old way of adding to frame, might be broken\n                #full.df[which(full.df[,1] %in% temp.dp.data$startDateTime),]<-temp.dp.data[which(full.df[,1] %in% temp.dp.data$startDateTime),]\n\n\n                #print(length(full.df[,1]))\n            }else{\n                temp.full.df<-data.frame(matrix(NA, nrow = length(ref_seq), ncol = length(colnames(temp.dp.data))))\n                names(temp.full.df)<-colnames(temp.dp.data)\n                temp.full.df[,1]<-as.POSIXct(ref_seq)\n\n                #New way?\n                #temp.full.df[which(full.df[,1] %in% temp.dp.data$startDateTime),]<-temp.dp.data[which(temp.dp.data$startDateTime %in% full.df[,1]),]\n\n                # The old way of adding to frame, might be broken\n                temp.full.df[which(full.df[,1] %in% temp.dp.data$startDateTime),]<-temp.dp.data[which(full.df[,1] %in% temp.dp.data$startDateTime),]\n\n                rm<-c(1,2)\n                full.df<-cbind(full.df, temp.full.df[,-rm])\n                #print(length(full.df[,1]))\n            }\n        }\n        #remove randow all na rows (artefacts, not gaps)\n        #full.df<-full.df[-which(is.na(full.df[,1])),]\n\n        #Make sure timestamps come out in order\n        #full.df<-full.df[order(full.df[,1]),]\n\n        file.path<-paste0(save.dir, file.name)\n        zip.dir<-gzfile(file.path)\n        write.csv(x=full.df, file=zip.dir, row.names = F)\n        return(full.df)\n\n    }else{\n        full.df<-read.csv(paste0(save.dir, file.name))\n        return(full.df)\n    }\n    rm(full.df)\n\n}\n",
    "created" : 1508945688040.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "202481517",
    "id" : "412364D1",
    "lastKnownWriteTime" : 1509033182,
    "last_content_update" : 1509033182108,
    "path" : "~/Dropbox/GitHub/Noble-Package/Noble/R/pull_data.R",
    "project_path" : "R/pull_data.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}